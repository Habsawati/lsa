{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2f4e86",
   "metadata": {},
   "source": [
    "## CRAWLING DATA PTA MANAJEMEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5e28ce",
   "metadata": {},
   "source": [
    "Web crawling adalah teknik pengumpulan data yang digunakan untuk mengindeks informasi pada halaman menggunakan URL (Uniform Resource Locator) dengan menyertakan API (Application Programming Interface) untuk melakukan penambangan dataset yang lebih besar. Web crawling adalah teknik pengumpulan data yang digunakan untuk mengindeks informasi pada halaman menggunakan URL (Uniform Resource Locator) dengan menyertakan API (Application Programming Interface) untuk melakukan penambangan dataset yang lebih besar. \n",
    "\n",
    "Pada tugas ini untuk melakukan crawling saya menggunakan library scrapy. Scrapy adalah framework Python untuk melakukan web scraping dalam skala besar. Scrapy menyediakan segala tools yang kita butuhkan untuk mengekstrak data dari setiap website secara efisien, memprosesnya, lalu menyimpannya dalam struktur atau format yang kita inginkan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019f9e1",
   "metadata": {},
   "source": [
    "import scrapy\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/080211100070',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/090211200001',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/080211100050',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/100211200002',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/080211100044',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/080211100119',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/080211100103',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/080211100098',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/090211100079',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/090211100089',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/090211100013',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/090211100020',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/090211100064',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/090211100064',\n",
    "            'https://pta.trunojoyo.ac.id/welcome/detail/090211100018'\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        # print(response.url)\n",
    "        yield {\n",
    "            'judul': response.css('#content_journal > ul > li > div:nth-child(2) > a::text').extract(),\n",
    "            'penulis': response.css('#content_journal > ul > li > div:nth-child(2) > div:nth-child(2) > span::text').extract(),\n",
    "            'dosen_pembimbing_1': response.css('#content_journal > ul > li > div:nth-child(2) > div:nth-child(3) > span::text').extract(),\n",
    "            'dosen_pembimbing_2': response.css('#content_journal > ul > li > div:nth-child(2) > div:nth-child(4) > span::text').extract(),\n",
    "            'abstrak': response.css('#content_journal > ul > li > div:nth-child(4) > div:nth-child(2) > p::text').extract(),\n",
    "        }\n",
    "        # content_journal > ul > li:nth-child(1) > div:nth-child(1) > a\n",
    "        # content_journal > ul > li:nth-child(1) > div:nth-child(1) > a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059c07b7",
   "metadata": {},
   "source": [
    "# Import Library yang Diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35dd6bae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m style\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#configure\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# sets matplotlib to inline and displays graphs below the corressponding cell.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for named entity recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0aacc1",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e45a8",
   "metadata": {},
   "source": [
    "Memanggil data berita yang telah kita crawling tadi dengan file CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b62da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('scrapylsa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76cef866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>penulis</th>\n",
       "      <th>dosen_pembimbing_1</th>\n",
       "      <th>dosen_pembimbing_2</th>\n",
       "      <th>abstrak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fenomenologi Relawan Kelompok Dukungan Sebaya ...</td>\n",
       "      <td>Penulis : Rina Astaria Mendrova</td>\n",
       "      <td>Dosen Pembimbing I : Dr. Yuliana Rakhmawati, S...</td>\n",
       "      <td>Dosen Pembimbing II :-</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KLASIFIKASI KOMPLEKSITAS VISUAL CITRA SAMPAH M...</td>\n",
       "      <td>Penulis : Afni Sakinah</td>\n",
       "      <td>Dosen Pembimbing I : Dr. Indah Agustien Siradj...</td>\n",
       "      <td>Dosen Pembimbing II :Moch. Kautsar Sophan, S.K...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PENENTUAN TINGKAT PRIORITAS PERBAIKAN MODE KEG...</td>\n",
       "      <td>Penulis : Lilis Kurnia Ikamawati</td>\n",
       "      <td>Dosen Pembimbing I : Dr. Kukuh Winarso, S.Si.,...</td>\n",
       "      <td>Dosen Pembimbing II :Issa Dyah Utami, S.T., M.T.</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analisis Cost Volume Profit Untuk Menentukan T...</td>\n",
       "      <td>Penulis : Husnul Hotimah</td>\n",
       "      <td>Dosen Pembimbing I : Hj. Evaliati Amaniyah, S....</td>\n",
       "      <td>Dosen Pembimbing II :</td>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HUBUNGAN ANTARA PROKRASTINASI AKADEMIK DENGAN ...</td>\n",
       "      <td>Penulis : ALIFIYA RIZKI LAILY</td>\n",
       "      <td>Dosen Pembimbing I : Fandi Rosi Sarwo Edi, S.K...</td>\n",
       "      <td>Dosen Pembimbing II :</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               judul  \\\n",
       "0  Fenomenologi Relawan Kelompok Dukungan Sebaya ...   \n",
       "1  KLASIFIKASI KOMPLEKSITAS VISUAL CITRA SAMPAH M...   \n",
       "2  PENENTUAN TINGKAT PRIORITAS PERBAIKAN MODE KEG...   \n",
       "3  Analisis Cost Volume Profit Untuk Menentukan T...   \n",
       "4  HUBUNGAN ANTARA PROKRASTINASI AKADEMIK DENGAN ...   \n",
       "\n",
       "                            penulis  \\\n",
       "0   Penulis : Rina Astaria Mendrova   \n",
       "1            Penulis : Afni Sakinah   \n",
       "2  Penulis : Lilis Kurnia Ikamawati   \n",
       "3          Penulis : Husnul Hotimah   \n",
       "4    Penulis : ALIFIYA RIZKI LAILY    \n",
       "\n",
       "                                  dosen_pembimbing_1  \\\n",
       "0  Dosen Pembimbing I : Dr. Yuliana Rakhmawati, S...   \n",
       "1  Dosen Pembimbing I : Dr. Indah Agustien Siradj...   \n",
       "2  Dosen Pembimbing I : Dr. Kukuh Winarso, S.Si.,...   \n",
       "3  Dosen Pembimbing I : Hj. Evaliati Amaniyah, S....   \n",
       "4  Dosen Pembimbing I : Fandi Rosi Sarwo Edi, S.K...   \n",
       "\n",
       "                                  dosen_pembimbing_2  \\\n",
       "0                             Dosen Pembimbing II :-   \n",
       "1  Dosen Pembimbing II :Moch. Kautsar Sophan, S.K...   \n",
       "2   Dosen Pembimbing II :Issa Dyah Utami, S.T., M.T.   \n",
       "3                              Dosen Pembimbing II :   \n",
       "4                              Dosen Pembimbing II :   \n",
       "\n",
       "                                             abstrak  \n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...  \n",
       "1  Klasifikasi citra merupakan proses pengelompok...  \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...  \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...  \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d15a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus kolom yang tidak digunakan.\n",
    "df.drop(['judul', 'penulis', 'dosen_pembimbing_1', 'dosen_pembimbing_2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b6d3509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ana Febrianti, 160521100004 Program Studi Sosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n16052110000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             abstrak\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...\n",
       "1  Klasifikasi citra merupakan proses pengelompok...\n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...\n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...\n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...\n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...\n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...\n",
       "7  Ana Febrianti, 160521100004 Program Studi Sosi...\n",
       "8  Nilai perusahaan merupakan bagian terpenting y...\n",
       "9  Abstrak – Farida Yulistiana Aji. \\n16052110000..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035238fe",
   "metadata": {},
   "source": [
    "# DATA CLEANING & PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a08b67",
   "metadata": {},
   "source": [
    "Text preprocessing adalah suatu proses untuk menyeleksi data text agar menjadi lebih terstruktur lagi dengan melalui serangkaian tahapan. Tapi, sesungguhnya tidak ada aturan pasti tentang setiap tahapan dalam text preprocessing. Semua itu tergantung dengan jenis serta kondisi data yang kita miliki. Text preprocessing merupakan salah satu implementasi dari text mining. Text mining sendiri adalah suatu kegiatan menambang data, dimana data yang biasanya diambil berupa text yang bersumber dari dokumen-dokumen yang memiliki goals untuk mencari kata kunci yang mewakili dari sekumpulan dokumen tersebut sehingga nantinya dapat dilakukan analisa hubungan antara dokumen-dokumen tersebut. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7642b",
   "metadata": {},
   "source": [
    "## Removing Number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab1038",
   "metadata": {},
   "source": [
    "Pada tahap ini akan melakukan penghapusan angka, untuk codenya dapat dilihat dibawah ini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be02b939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak</th>\n",
       "      <th>remov number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ana Febrianti, 160521100004 Program Studi Sosi...</td>\n",
       "      <td>Ana Febrianti,  Program Studi Sosiologi, Fakul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n16052110000...</td>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n. Program S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             abstrak  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti, 160521100004 Program Studi Sosi...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak – Farida Yulistiana Aji. \\n16052110000...   \n",
       "\n",
       "                                        remov number  \n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...  \n",
       "1  Klasifikasi citra merupakan proses pengelompok...  \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...  \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...  \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...  \n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...  \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...  \n",
       "7  Ana Febrianti,  Program Studi Sosiologi, Fakul...  \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...  \n",
       "9  Abstrak – Farida Yulistiana Aji. \\n. Program S...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "import re #regex library\n",
    "\n",
    "# import word_tokenize & FreqDist from NLTK\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "df['remov number'] = df['abstrak'].apply(remove_number)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc806b8",
   "metadata": {},
   "source": [
    "## Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e55e5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak</th>\n",
       "      <th>remov number</th>\n",
       "      <th>remov all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "      <td>ABSTRAK Penelitian ini bertujuan untuk mengeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "      <td>ABSTRAK Tujuan penelitian ini adalah untuk men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ana Febrianti, 160521100004 Program Studi Sosi...</td>\n",
       "      <td>Ana Febrianti,  Program Studi Sosiologi, Fakul...</td>\n",
       "      <td>Ana Febrianti, Program Studi Sosiologi, Fakult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n16052110000...</td>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n. Program S...</td>\n",
       "      <td>Abstrak ? Farida Yulistiana Aji. . Program Stu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             abstrak  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti, 160521100004 Program Studi Sosi...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak – Farida Yulistiana Aji. \\n16052110000...   \n",
       "\n",
       "                                        remov number  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti,  Program Studi Sosiologi, Fakul...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak – Farida Yulistiana Aji. \\n. Program S...   \n",
       "\n",
       "                                           remov all  \n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...  \n",
       "1  Klasifikasi citra merupakan proses pengelompok...  \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...  \n",
       "3  ABSTRAK Penelitian ini bertujuan untuk mengeta...  \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...  \n",
       "5  ABSTRAK Tujuan penelitian ini adalah untuk men...  \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...  \n",
       "7  Ana Febrianti, Program Studi Sosiologi, Fakult...  \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...  \n",
       "9  Abstrak ? Farida Yulistiana Aji. . Program Stu...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_all(text):\n",
    "    # remove tab, new line, ans back slice\n",
    "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "    # remove non ASCII (emoticon, chinese word, .etc)\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    # remove mention, link, hashtag\n",
    "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "    # remove incomplete URL\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "df['remov all'] = df['remov number'].apply(remove_all)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b1ca19",
   "metadata": {},
   "source": [
    "Pada tahap prepocessing selanjutnya akan melakukan removing punctuation seperti menghapus simbol dan tanda baca yang tidak penting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8f025ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak</th>\n",
       "      <th>remov number</th>\n",
       "      <th>remov all</th>\n",
       "      <th>remov punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak  Tujuan dari penelitian ini adalah men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "      <td>ABSTRAK Penelitian ini bertujuan untuk mengeta...</td>\n",
       "      <td>ABSTRAK Penelitian ini bertujuan untuk mengeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "      <td>ABSTRAK Tujuan penelitian ini adalah untuk men...</td>\n",
       "      <td>ABSTRAK Tujuan penelitian ini adalah untuk men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan keterampi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ana Febrianti, 160521100004 Program Studi Sosi...</td>\n",
       "      <td>Ana Febrianti,  Program Studi Sosiologi, Fakul...</td>\n",
       "      <td>Ana Febrianti, Program Studi Sosiologi, Fakult...</td>\n",
       "      <td>Ana Febrianti Program Studi Sosiologi Fakultas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n16052110000...</td>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n. Program S...</td>\n",
       "      <td>Abstrak ? Farida Yulistiana Aji. . Program Stu...</td>\n",
       "      <td>Abstrak  Farida Yulistiana Aji  Program Studi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             abstrak  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti, 160521100004 Program Studi Sosi...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak – Farida Yulistiana Aji. \\n16052110000...   \n",
       "\n",
       "                                        remov number  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti,  Program Studi Sosiologi, Fakul...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak – Farida Yulistiana Aji. \\n. Program S...   \n",
       "\n",
       "                                           remov all  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK Penelitian ini bertujuan untuk mengeta...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK Tujuan penelitian ini adalah untuk men...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti, Program Studi Sosiologi, Fakult...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak ? Farida Yulistiana Aji. . Program Stu...   \n",
       "\n",
       "                                         remov punct  \n",
       "0  Abstrak  Tujuan dari penelitian ini adalah men...  \n",
       "1  Klasifikasi citra merupakan proses pengelompok...  \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...  \n",
       "3  ABSTRAK Penelitian ini bertujuan untuk mengeta...  \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...  \n",
       "5  ABSTRAK Tujuan penelitian ini adalah untuk men...  \n",
       "6  Literasi zakat merupakan pengetahuan keterampi...  \n",
       "7  Ana Febrianti Program Studi Sosiologi Fakultas...  \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...  \n",
       "9  Abstrak  Farida Yulistiana Aji  Program Studi ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation(simbol dan tanda baca)\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "df['remov punct'] = df['remov all'].apply(remove_punctuation)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bab038",
   "metadata": {},
   "source": [
    "## Stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec70aed",
   "metadata": {},
   "source": [
    "Tahap selanjutnya untuk prepocessing adalah tahapan filtering yang digunakan untuk mengambil kata-kata yang penting dari hasil token tadi. Kata umum yang biasanya muncul dan tidak memiliki makna disebut dengan stopword. Misalnya penggunaan kata penghubung seperti dan, yang,serta, setelah, dan lainnya. Penghilangan stopword ini dapat mengurangi ukuran index dan waktu pemrosesan. Selain itu, juga dapat mengurangi level noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef088200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(headline):\n",
    "  le=WordNetLemmatizer()\n",
    "  word_tokens=word_tokenize(headline)\n",
    "  tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "  cleaned_text=\" \".join(tokens)\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cab12607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time taking\n",
    "df['stopword']=df['remov punct'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2fda858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak</th>\n",
       "      <th>remov number</th>\n",
       "      <th>remov all</th>\n",
       "      <th>remov punct</th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstrak  Tujuan dari penelitian ini adalah men...</td>\n",
       "      <td>Abstrak Tujuan penelitian fenomena dialami Kel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra merupakan proses pengelompok...</td>\n",
       "      <td>Klasifikasi citra prose pengelompokan piksel c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian ini berlokasikan di PT Semen Indone...</td>\n",
       "      <td>Penelitian berlokasikan Semen Indonesia Pabrik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "      <td>ABSTRAK\\nPenelitian ini bertujuan untuk menget...</td>\n",
       "      <td>ABSTRAK Penelitian ini bertujuan untuk mengeta...</td>\n",
       "      <td>ABSTRAK Penelitian ini bertujuan untuk mengeta...</td>\n",
       "      <td>ABSTRAK Penelitian bertujuan perhitungan tingk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian ini bertujuan untuk mengetahui hubu...</td>\n",
       "      <td>Penelitian bertujuan hubungan prokrastinasi ak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "      <td>ABSTRAK\\nTujuan penelitian ini adalah untuk me...</td>\n",
       "      <td>ABSTRAK Tujuan penelitian ini adalah untuk men...</td>\n",
       "      <td>ABSTRAK Tujuan penelitian ini adalah untuk men...</td>\n",
       "      <td>ABSTRAK Tujuan penelitian pengaruh faktor kual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan, keteramp...</td>\n",
       "      <td>Literasi zakat merupakan pengetahuan keterampi...</td>\n",
       "      <td>Literasi zakat pengetahuan keterampilan keyaki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ana Febrianti, 160521100004 Program Studi Sosi...</td>\n",
       "      <td>Ana Febrianti,  Program Studi Sosiologi, Fakul...</td>\n",
       "      <td>Ana Febrianti, Program Studi Sosiologi, Fakult...</td>\n",
       "      <td>Ana Febrianti Program Studi Sosiologi Fakultas...</td>\n",
       "      <td>Febrianti Program Studi Sosiologi Fakultas Ilm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan merupakan bagian terpenting y...</td>\n",
       "      <td>Nilai perusahaan terpenting investor calon inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n16052110000...</td>\n",
       "      <td>Abstrak – Farida Yulistiana Aji. \\n. Program S...</td>\n",
       "      <td>Abstrak ? Farida Yulistiana Aji. . Program Stu...</td>\n",
       "      <td>Abstrak  Farida Yulistiana Aji  Program Studi ...</td>\n",
       "      <td>Abstrak Farida Yulistiana Program Studi Sosiol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             abstrak  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti, 160521100004 Program Studi Sosi...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak – Farida Yulistiana Aji. \\n16052110000...   \n",
       "\n",
       "                                        remov number  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK\\nPenelitian ini bertujuan untuk menget...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK\\nTujuan penelitian ini adalah untuk me...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti,  Program Studi Sosiologi, Fakul...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak – Farida Yulistiana Aji. \\n. Program S...   \n",
       "\n",
       "                                           remov all  \\\n",
       "0  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK Penelitian ini bertujuan untuk mengeta...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK Tujuan penelitian ini adalah untuk men...   \n",
       "6  Literasi zakat merupakan pengetahuan, keteramp...   \n",
       "7  Ana Febrianti, Program Studi Sosiologi, Fakult...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak ? Farida Yulistiana Aji. . Program Stu...   \n",
       "\n",
       "                                         remov punct  \\\n",
       "0  Abstrak  Tujuan dari penelitian ini adalah men...   \n",
       "1  Klasifikasi citra merupakan proses pengelompok...   \n",
       "2  Penelitian ini berlokasikan di PT Semen Indone...   \n",
       "3  ABSTRAK Penelitian ini bertujuan untuk mengeta...   \n",
       "4  Penelitian ini bertujuan untuk mengetahui hubu...   \n",
       "5  ABSTRAK Tujuan penelitian ini adalah untuk men...   \n",
       "6  Literasi zakat merupakan pengetahuan keterampi...   \n",
       "7  Ana Febrianti Program Studi Sosiologi Fakultas...   \n",
       "8  Nilai perusahaan merupakan bagian terpenting y...   \n",
       "9  Abstrak  Farida Yulistiana Aji  Program Studi ...   \n",
       "\n",
       "                                            stopword  \n",
       "0  Abstrak Tujuan penelitian fenomena dialami Kel...  \n",
       "1  Klasifikasi citra prose pengelompokan piksel c...  \n",
       "2  Penelitian berlokasikan Semen Indonesia Pabrik...  \n",
       "3  ABSTRAK Penelitian bertujuan perhitungan tingk...  \n",
       "4  Penelitian bertujuan hubungan prokrastinasi ak...  \n",
       "5  ABSTRAK Tujuan penelitian pengaruh faktor kual...  \n",
       "6  Literasi zakat pengetahuan keterampilan keyaki...  \n",
       "7  Febrianti Program Studi Sosiologi Fakultas Ilm...  \n",
       "8  Nilai perusahaan terpenting investor calon inv...  \n",
       "9  Abstrak Farida Yulistiana Program Studi Sosiol...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f82d496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstrak Tujuan penelitian fenomena dialami Kel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klasifikasi citra prose pengelompokan piksel c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penelitian berlokasikan Semen Indonesia Pabrik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABSTRAK Penelitian bertujuan perhitungan tingk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penelitian bertujuan hubungan prokrastinasi ak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABSTRAK Tujuan penelitian pengaruh faktor kual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Literasi zakat pengetahuan keterampilan keyaki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Febrianti Program Studi Sosiologi Fakultas Ilm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nilai perusahaan terpenting investor calon inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abstrak Farida Yulistiana Program Studi Sosiol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            stopword\n",
       "0  Abstrak Tujuan penelitian fenomena dialami Kel...\n",
       "1  Klasifikasi citra prose pengelompokan piksel c...\n",
       "2  Penelitian berlokasikan Semen Indonesia Pabrik...\n",
       "3  ABSTRAK Penelitian bertujuan perhitungan tingk...\n",
       "4  Penelitian bertujuan hubungan prokrastinasi ak...\n",
       "5  ABSTRAK Tujuan penelitian pengaruh faktor kual...\n",
       "6  Literasi zakat pengetahuan keterampilan keyaki...\n",
       "7  Febrianti Program Studi Sosiologi Fakultas Ilm...\n",
       "8  Nilai perusahaan terpenting investor calon inv...\n",
       "9  Abstrak Farida Yulistiana Program Studi Sosiol..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Menghapus kolom isi, remov number dan remov punct\n",
    "df.drop(['abstrak', 'remov number', 'remov all', 'remov punct'],axis=1,inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f0aa3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstrak tujuan penelitian fenomena dialami kel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klasifikasi citra prose pengelompokan piksel c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>penelitian berlokasikan semen indonesia pabrik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstrak penelitian bertujuan perhitungan tingk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>penelitian bertujuan hubungan prokrastinasi ak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abstrak tujuan penelitian pengaruh faktor kual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>literasi zakat pengetahuan keterampilan keyaki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>febrianti program studi sosiologi fakultas ilm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nilai perusahaan terpenting investor calon inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abstrak farida yulistiana program studi sosiol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            stopword\n",
       "0  abstrak tujuan penelitian fenomena dialami kel...\n",
       "1  klasifikasi citra prose pengelompokan piksel c...\n",
       "2  penelitian berlokasikan semen indonesia pabrik...\n",
       "3  abstrak penelitian bertujuan perhitungan tingk...\n",
       "4  penelitian bertujuan hubungan prokrastinasi ak...\n",
       "5  abstrak tujuan penelitian pengaruh faktor kual...\n",
       "6  literasi zakat pengetahuan keterampilan keyaki...\n",
       "7  febrianti program studi sosiologi fakultas ilm...\n",
       "8  nilai perusahaan terpenting investor calon inv...\n",
       "9  abstrak farida yulistiana program studi sosiol..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mengubah huruf menjadi kecil dengan menggunakan Series.str.lower() pada pandas\n",
    "\n",
    "df['stopword'] = df['stopword'].str.lower()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "793d98f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abstrak tujuan penelitian fenomena dialami kelompok dukungan sebaya pasien odha orang hivaids pengembalian self esteem pengalaman menjalani kehidupan sosial hivaids penelitian metode kualitatif fenomenologi informan penelitian orang pasien relawan dokter konsultan hivaids metode pengumpulan data observasi wawancara dokumen objek penelitian selfesteem odha relawan kelompok dukungan sebaya edukasi menunakan komunikasi terapeutik teknik analisis data metode interpretative phenomenology analysis tujuan penggunaan metode penelitian kualitatif gambaran pengalaman hidup hivaids hasil penelitian pasien odha diberitahukan status hivaids dokter mengalami selfesteem penurunan disebabkan faktor stigma diskriminasi penolakan penolakan keluarga adanya berguna menguatkan odha mengedukasi odha keluarga odha membantu tenaga kesehatan sosialisasi hivaids odha terapi menerima percaya memberdayakan kata kunci selfesteem odha hivaids fenomenologi'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melihat data ke-0\n",
    "df['stopword'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22c65371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"abstrak_prepocessing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e0cd7",
   "metadata": {},
   "source": [
    "## MENGEKSTRAK FITUR DAN MEMBUAT DOCUMENT-TERM-MATRIX ( DTM )\n",
    "Dalam DTM nilainya adalah nilai TFidf. Term Frequency — Inverse Document Frequency atau TFIDF adalah suatu metode algoritma yang berguna untuk menghitung bobot setiap kata yang umum digunakan. Metode ini juga terkenal efisien, mudah dan memiliki hasil yang akurat. Secara sederhana, metode TF-IDF digunakan untuk mengetahui berapa sering suatu kata muncul di dalam dokumen. Contoh yang dibahas kali ini adalah mengenai penentuan urutan peringkat data berdasarkan query yang digunakan.\n",
    "\n",
    "Inti utama dari algoritma ini adalah melakukan perhitungan nilai TF dan nilai IDF dari setiap kata kunci terhadap masing-masing dokumen dalam korpus. \n",
    "\n",
    "Term Frequency (TF) yaitu pembobotan/weight setiap kata (term) pada suatu dokumen berdasarkan jumlah kemunculannya dalam dokumen tersebut. Semakin besar jumlah kemunculan suatu kata dalam dokumen, maka semakin besar pula bobot yang diberikan (TF Tinggi) jadi nilai tertinggi merupakan  jumlah kemunculan/frekuensi.\n",
    "\n",
    "Setelah menentukan Tf maka selanjutnya kita tentukan nilai IDF nya dapat dihitung dengan rumus :\n",
    "$$\n",
    "\\operatorname{idf}=\\log \\left(\\frac{D}{d f}\\right)\n",
    "$$\n",
    "\n",
    "Selanjutnya adalah melakukan perkalian antara nilai TF dan IDF untuk mendapatkan jawaban akhir. untuk rumusnya sebagai berikut:\n",
    "$$\n",
    "\\begin{gathered}\n",
    "Tf-Idf=t f_{i j} * i d f_{j} \\\\\n",
    "Tf-Idf=t f_{i j} * \\log \\left(\\frac{D}{d f}\\right)\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "Keterangan :\n",
    "Dimana D adalah jumlah semua dokumen dalam koleksi sedangkan df adalah jumlah dokumen yang mengandung term tertentu.\n",
    "\n",
    "Parameter dari vectorizer Tfidf mmiliki beberapa poin penting:\n",
    "1) LSA umumnya diimplementasikan dengan nilai Tfidf di mana-mana dan tidak dengan Count Vectorizer.\n",
    "\n",
    "2) max_features tergantung pada daya komputasi Anda dan juga pada eval. metrik (skor koherensi adalah metrik untuk model topik). Coba nilai yang memberikan evaluasi terbaik. metrik dan tidak membatasi kekuatan pemrosesan.\n",
    "\n",
    "3) Nilai default untuk min_df & max_df bekerja dengan baik.\n",
    "\n",
    "4) Dapat mencoba nilai yang berbeda untuk ngram_range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f3eff68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstrak_akhir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstrak tujuan penelitian fenomena dialami kel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klasifikasi citra prose pengelompokan piksel c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>penelitian berlokasikan semen indonesia pabrik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstrak penelitian bertujuan perhitungan tingk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>penelitian bertujuan hubungan prokrastinasi ak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       abstrak_akhir\n",
       "0  abstrak tujuan penelitian fenomena dialami kel...\n",
       "1  klasifikasi citra prose pengelompokan piksel c...\n",
       "2  penelitian berlokasikan semen indonesia pabrik...\n",
       "3  abstrak penelitian bertujuan perhitungan tingk...\n",
       "4  penelitian bertujuan hubungan prokrastinasi ak..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"abstrak_prepocessing.csv\", usecols=[\"stopword\"])\n",
    "df.columns = [\"abstrak_akhir\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aea054f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  {'abstrak': 0, 'tujuan': 687, 'penelitian': 482, 'fenomena': 162, 'dialami': 105, 'kelompok': 254, 'dukungan': 143, 'sebaya': 591, 'pasien': 457, 'odha': 437, 'orang': 442, 'hivaids': 189, 'pengembalian': 493, 'self': 603, 'esteem': 150, 'pengalaman': 483, 'menjalani': 405, 'kehidupan': 250, 'sosial': 634, 'metode': 416, 'kualitatif': 300, 'fenomenologi': 163, 'informan': 202, 'relawan': 568, 'dokter': 136, 'konsultan': 293, 'pengumpulan': 500, 'data': 94, 'observasi': 435, 'wawancara': 705, 'dokumen': 137, 'objek': 434, 'selfesteem': 604, 'edukasi': 145, 'menunakan': 408, 'komunikasi': 287, 'terapeutik': 661, 'teknik': 656, 'analisis': 19, 'interpretative': 207, 'phenomenology': 537, 'analysis': 22, 'penggunaan': 495, 'gambaran': 173, 'hidup': 187, 'hasil': 184, 'diberitahukan': 110, 'status': 640, 'mengalami': 379, 'penurunan': 508, 'disebabkan': 127, 'faktor': 152, 'stigma': 641, 'diskriminasi': 131, 'penolakan': 505, 'keluarga': 256, 'adanya': 3, 'berguna': 50, 'menguatkan': 400, 'mengedukasi': 385, 'membantu': 359, 'tenaga': 658, 'kesehatan': 267, 'sosialisasi': 635, 'terapi': 662, 'menerima': 377, 'percaya': 516, 'memberdayakan': 360, 'kata': 236, 'kunci': 307, 'klasifikasi': 282, 'citra': 81, 'prose': 554, 'pengelompokan': 491, 'piksel': 538, 'kelas': 251, 'memiliki': 364, 'batasan': 38, 'setiap': 612, 'label': 310, 'fitur': 165, 'khas': 277, 'dijadikan': 117, 'perwakilan': 536, 'kelasnya': 252, 'mempermudah': 368, 'pelabelan': 461, 'pada': 446, 'sampah': 584, 'pemberlakuan': 473, 'tingkat': 675, 'kompleksitas': 286, 'kepadatan': 257, 'proses': 555, 'feature': 159, 'learning': 319, 'convolutional': 85, 'neural': 431, 'network': 430, 'dikombinasikan': 118, 'nilai': 433, 'tambahan': 653, 'handcrafted': 181, 'features': 160, 'structure': 643, 'diekstrak': 114, 'deteksi': 103, 'tepi': 660, 'operator': 441, 'lapacian': 314, 'diversity': 135, 'sudut': 646, 'algoritma': 14, 'fast': 158, 'from': 168, 'accelerated': 2, 'segment': 595, 'test': 671, 'fiturfitur': 166, 'digabungkan': 115, 'fully': 170, 'connected': 84, 'layer': 316, 'didapatkan': 113, 'keluaran': 255, 'dataset': 95, 'diambil': 106, 'google': 176, 'image': 196, 'dibagi': 108, 'training': 681, 'terdapat': 665, 'skenario': 627, 'coba': 83, 'pengaruh': 487, 'menghasilkan': 395, 'ratarata': 563, 'fscore': 169, 'tertinggi': 670, 'asli': 27, 'augmentasi': 30, 'model': 422, 'peningkatan': 502, 'akurasi': 11, 'kombinasi': 285, 'dari': 92, 'disimpulkan': 129, 'kinerja': 280, 'sistem': 624, 'berlokasikan': 55, 'semen': 606, 'indonesia': 201, 'pabrik': 444, 'tuban': 685, 'unit': 693, 'kerja': 263, 'packer': 445, 'jenis': 221, 'kerusakan': 264, 'mesin': 413, 'dapa': 91, 'mengganggu': 392, 'operasional': 440, 'mematikan': 356, 'produksi': 550, 'pengantongan': 486, 'lini': 326, 'pengemasan': 492, 'pengisian': 496, 'memprioritaskan': 371, 'risiko': 576, 'jalannya': 214, 'fuzzy': 171, 'fmea': 167, 'topsis': 679, 'hasilnya': 185, 'fuzzyfmea': 172, 'terbesar': 663, 'berhentinya': 51, 'spout': 637, 'mati': 347, 'sedangakan': 593, 'pengolahan': 497, 'reject': 567, 'baut': 39, 'soft': 631, 'jurnal': 224, 'putus': 561, 'bertujuan': 62, 'perhitungan': 519, 'hunian': 194, 'kamar': 227, 'hotel': 191, 'panglima': 453, 'sampang': 585, 'cost': 86, 'volume': 703, 'profit': 551, 'menentukan': 376, 'break': 70, 'event': 151, 'point': 541, 'margin': 342, 'safetytingkat': 581, 'bata': 37, 'aman': 16, 'menurunkan': 410, 'penjualan': 503, 'deskriptif': 102, 'berasal': 45, 'studi': 644, 'pustaka': 560, 'obyek': 436, 'safety': 580, 'memprediksi': 370, 'hubungan': 193, 'prokrastinasi': 553, 'akademik': 8, 'burnout': 75, 'perilaku': 520, 'plagiarisme': 540, 'mahasiswa': 334, 'psikologi': 556, 'subjek': 645, 'aktif': 9, 'kuliah': 305, 'sampel': 586, 'insidental': 204, 'sampling': 587, 'skala': 626, 'likert': 323, 'korelasi': 298, 'product': 548, 'moment': 423, 'bantuan': 35, 'program': 552, 'spss': 638, 'window': 709, 'berdasarkan': 48, 'diperoleh': 124, 'hipotesis': 188, 'diterima': 132, 'signifikansi': 621, 'koefisien': 284, 'sehingga': 596, 'kualitas': 299, 'produk': 549, 'harga': 182, 'keputusan': 260, 'pembelian': 469, 'parsial': 455, 'simultan': 623, 'perspektif': 530, 'ekonomi': 148, 'islam': 211, 'method': 415, 'dimana': 120, 'menggabungkan': 390, 'kuantitatif': 302, 'bersifat': 60, 'sumber': 649, 'primer': 546, 'sekunder': 602, 'variabel': 701, 'dependent': 98, 'independent': 198, 'kuesioner': 304, 'regresi': 566, 'linier': 327, 'berganda': 49, 'secara': 592, 'berpengaruh': 57, 'signifikan': 620, 'sedangkan': 594, 'literasi': 328, 'zakat': 711, 'pengetahuan': 494, 'keterampilan': 272, 'keyakinan': 276, 'mempengaruhi': 366, 'sikap': 622, 'meningkatkan': 404, 'pengambilan': 484, 'penyaluran': 512, 'lembaga': 320, 'amil': 17, 'analitis': 21, 'masyarakat': 344, 'derah': 100, 'perkotaan': 522, 'lazismu': 317, 'pamekasan': 451, 'semiterstruktur': 607, 'disiapkan': 128, 'menggali': 391, 'informasi': 203, 'nasabah': 428, 'tahapan': 652, 'reduksi': 565, 'penyajian': 511, 'penarikan': 477, 'kesimpulan': 268, 'tingkatan': 676, 'berbedabeda': 47, 'oleh': 439, 'kategori': 237, 'well': 706, 'literate': 329, 'sufficient': 647, 'le': 318, 'keuangan': 275, 'pengelola': 489, 'febrianti': 161, 'sosiologi': 636, 'fakultas': 154, 'ilmu': 195, 'budaya': 72, 'universitas': 694, 'trunojoyo': 683, 'madura': 332, 'jaringan': 215, 'pengusaha': 501, 'kerajinan': 261, 'limbah': 324, 'kayu': 239, 'jati': 217, 'dosen': 141, 'pembimbing': 474, 'khoirul': 278, 'rosyadi': 577, 'jatisubjek': 219, 'pengrajin': 498, 'pembeli': 468, 'jatimetode': 218, 'dokumentasiinforman': 139, 'dipilih': 125, 'purposive': 559, 'miles': 418, 'huberman': 192, 'pemeriksaan': 475, 'keabsahan': 240, 'triangulasi': 682, 'sumberdalam': 650, 'menganalisis': 380, 'teori': 659, 'marc': 339, 'granovetter': 177, 'didalam': 112, 'desa': 101, 'pembelidisamping': 470, 'bentukbentuk': 43, 'persaudaraan': 528, 'kuat': 303, 'persahabatan': 527, 'kesamaan': 266, 'tinggal': 674, 'strategi': 642, 'pemasaran': 465, 'memasarkan': 355, 'barang': 36, 'mengikuti': 397, 'pameran': 452, 'menyebar': 411, 'kartu': 234, 'nama': 427, 'kerajinannya': 262, 'shorum': 615, 'miliknya': 419, 'medium': 350, 'whatsapp': 707, 'perusahaan': 534, 'terpenting': 667, 'investor': 209, 'calon': 77, 'menanamkan': 372, 'dananya': 90, 'semakin': 605, 'berkembangnya': 53, 'dunia': 144, 'investasi': 208, 'terdaftar': 664, 'jakarta': 213, 'islamic': 212, 'index': 199, 'memperoleh': 369, 'dana': 89, 'mengembangkan': 388, 'usahanya': 697, 'adapun': 4, 'indikator': 200, 'menilai': 403, 'asset': 28, 'growth': 178, 'current': 87, 'ratio': 564, 'debt': 97, 'equity': 149, 'peneliti': 481, 'tertarik': 669, 'meliputi': 352, 'laporan': 315, 'kapitalisasi': 231, 'pasar': 456, 'kurs': 308, 'dolar': 140, 'penutupan': 509, 'populasi': 542, 'konsisten': 291, 'asumsi': 29, 'klasik': 283, 'linear': 325, 'determinan': 104, 'presentase': 545, 'dipengaruhi': 123, 'negatif': 429, 'positif': 543, 'farida': 155, 'yulistiana': 710, 'pertukaran': 532, 'tradisi': 680, 'sape': 588, 'toktok': 677, 'perayaan': 514, 'pernikahan': 525, 'bringen': 71, 'kecamatan': 243, 'labang': 309, 'kabupaten': 226, 'bangkalan': 34, 'budayawan': 73, 'pelaku': 462, 'dalam': 88, 'dokumentasi': 138, 'marcell': 340, 'mauss': 348, 'pemberian': 472, 'seserahan': 610, 'pengantin': 485, 'laki': 311, 'menyebutnya': 412, 'manten': 337, 'lengkap': 321, 'mewah': 417, 'membutuhkan': 362, 'siang': 616, 'bersamaan': 59, 'iringan': 210, 'perempuan': 518, 'membalasnya': 357, 'balasan': 33, 'setimpal': 613, 'malam': 336, 'hiburan': 186, 'mengundang': 401, 'menghadiri': 394, 'memeriahkan': 363, 'resepsi': 570, 'pernikahannya': 526, 'makna': 335, 'tersendiri': 668, 'mengangkat': 381, 'drajat': 142, 'masingmasing': 343, 'rumah': 579, 'sakit': 582, 'salah': 583, 'instansi': 205, 'bidang': 64, 'pelayanan': 463, 'jasa': 216, 'beroprasi': 56, 'penuh': 506, 'perawat': 513, 'memadai': 353, 'pekerjaan': 460, 'lepas': 322, 'shift': 614, 'rsud': 578, 'soetomo': 630, 'menggunkan': 393, 'pembagian': 466, 'pagi': 449, 'sore': 633, 'mengevaluasi': 389, 'kelelahan': 253, 'bourdon': 69, 'wiersma': 708, 'penlitian': 504, 'mengindikasikan': 398, 'value': 700, 'kecepatan': 245, 'ketelitian': 270, 'konsistensi': 292, 'dibandingkan': 109, 'solusi': 632, 'usulan': 699, 'meminimasi': 365, 'lantai': 313, 'pengaturan': 488, 'usia': 698, 'sesuai': 611, 'penambahan': 476, 'daya': 96, 'ketenagakerjaan': 271, 'keperawatan': 258, 'mengurangi': 402, 'beban': 40, 'pendapatan': 479, 'bopo': 67, 'loan': 330, 'deposit': 99, 'return': 574, 'capital': 78, 'adequacy': 5, 'sektor': 601, 'perbankan': 515, 'bursa': 76, 'efek': 146, 'periode': 521, 'pendekatan': 480, 'perusahaanteknik': 535, 'untuk': 695, 'kontribusi': 294, 'independen': 197, 'pengujian': 499, 'kepercayaan': 259, 'mennunjukkan': 406, 'bopoldr': 68, 'gerakan': 174, 'permasalahan': 524, 'ketersediaan': 273, 'pengelolaan': 490, 'sumberdaya': 651, 'berkaitan': 52, 'skripsi': 628, 'praktik': 544, 'mobilisasi': 420, 'bacatulis': 31, 'serikat': 609, 'peduli': 458, 'anggotaanggota': 24, 'karakteristik': 232, 'ditetapkan': 133, 'resource': 571, 'mobilization': 421, 'theory': 672, 'landasan': 312, 'analisisnya': 20, 'agregasi': 6, 'kooptasi': 296, 'mekanisme': 351, 'ak': 7, 'aktoraktor': 10, 'bacatulisnya': 32, 'moral': 424, 'menunjukan': 409, 'loyalitas': 331, 'berlebih': 54, 'kultural': 306, 'ngopi': 432, 'organisasi': 443, 'pemanfaatan': 464, 'fasilitas': 157, 'publik': 557, 'komunitas': 288, 'manusia': 338, 'kedekatan': 247, 'personal': 529, 'material': 346, 'uang': 692, 'warung': 704, 'kopi': 297, 'buku': 74, 'bertahan': 61, 'pemberdayaan': 471, 'kampanye': 228, 'bekerjasama': 41, 'membangun': 358, 'berbasis': 46, 'membingkai': 361, 'musik': 426, 'penyadaran': 510, 'tulisan': 688, 'respon': 572, 'siswa': 625, 'rendah': 569, 'pembelajaran': 467, 'daring': 93, 'dihadapi': 116, 'upaya': 696, 'sekolahorang': 600, 'guru': 180, 'mengatasi': 382, 'tunjung': 690, 'kuantatif': 301, 'responden': 573, 'angketkuesioner': 25, 'tunggal': 689, 'problematika': 547, 'kebanyakan': 241, 'berpenghasilan': 58, 'ribu': 575, 'jutabulan': 225, 'anggapan': 23, 'biaya': 63, 'paket': 450, 'internet': 206, 'mahal': 333, 'alatalat': 13, 'teknologi': 657, 'menemani': 375, 'belajar': 42, 'kecuali': 246, 'pegawai': 459, 'jenuh': 222, 'kesulitan': 269, 'memahami': 354, 'mengeluhkan': 387, 'materi': 345, 'dinilai': 121, 'mencatat': 374, 'dibuku': 111, 'catatan': 79, 'aplikasi': 26, 'variatif': 702, 'ceramahmenyuruh': 80, 'menonton': 407, 'tvri': 691, 'fasih': 156, 'grub': 179, 'satunya': 590, 'signal': 619, 'stabil': 639, 'anak': 18, 'mengawasi': 384, 'sulit': 648, 'dipahami': 122, 'jenuhsering': 223, 'mengeluh': 386, 'kondisinya': 290, 'penunjangupaya': 507, 'mencapai': 373, 'kkmmenyediakan': 281, 'alat': 12, 'harganya': 183, 'sejauh': 597, 'berani': 44, 'disiplin': 130, 'ditingkatkan': 134, 'kesadaran': 265, 'sendri': 608, 'alternatif': 15, 'tugas': 686, 'karya': 235, 'sekolah': 599, 'menghubungi': 396, 'dianjurkan': 107, 'mengatur': 383, 'pertemuan': 531, 'mengajarkan': 378, 'classroom': 82, 'tuawali': 684, 'murid': 425, 'biochar': 65, 'padatan': 447, 'kaya': 238, 'kandungan': 230, 'karbon': 233, 'konversi': 295, 'biomassa': 66, 'pirolisis': 539, 'pencampuran': 478, 'pupuk': 558, 'kandang': 229, 'efektivitas': 147, 'memperbaiki': 367, 'sifatsifat': 618, 'tanah': 654, 'mengkaji': 399, 'sekam': 598, 'padi': 448, 'sapi': 589, 'sifat': 617, 'fisik': 164, 'kimia': 279, 'mediteran': 349, 'tanaman': 655, 'kedelai': 248, 'glycine': 175, 'dilaksanakan': 119, 'kebun': 242, 'hortikultura': 190, 'socah': 629, 'jawa': 220, 'timur': 673, 'terletak': 666, 'ketinggian': 274, 'meter': 414, 'oktober': 438, 'maret': 341, 'percobaan': 517, 'dirancang': 126, 'rancangan': 562, 'acak': 1, 'faktorial': 153, 'tonha': 678, 'pertumbuhan': 533, 'parameter': 454, 'kecenderungan': 244, 'kondisi': 289, 'kedele': 249, 'perlakuan': 523}\n",
      "Encoded Document is:\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "document = df['abstrak_akhir']\n",
    "a=len(document)\n",
    "\n",
    "# Create a Vectorizer Object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit(document)\n",
    "\n",
    "# Printing the identified Unique words along with their indices\n",
    "print(\"Vocabulary: \", vectorizer.vocabulary_)\n",
    "\n",
    "# Encode the Document\n",
    "vector = vectorizer.transform(document)\n",
    "\n",
    "# Summarizing the Encoded Texts\n",
    "print(\"Encoded Document is:\")\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0df6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36ba49",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe95c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "tf = tfidf.fit_transform(vectorizer.fit_transform(document)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "765f9ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>abstrak</th>\n",
       "      <th>acak</th>\n",
       "      <th>accelerated</th>\n",
       "      <th>adanya</th>\n",
       "      <th>adapun</th>\n",
       "      <th>adequacy</th>\n",
       "      <th>agregasi</th>\n",
       "      <th>ak</th>\n",
       "      <th>akademik</th>\n",
       "      <th>aktif</th>\n",
       "      <th>...</th>\n",
       "      <th>variatif</th>\n",
       "      <th>volume</th>\n",
       "      <th>warung</th>\n",
       "      <th>wawancara</th>\n",
       "      <th>well</th>\n",
       "      <th>whatsapp</th>\n",
       "      <th>wiersma</th>\n",
       "      <th>window</th>\n",
       "      <th>yulistiana</th>\n",
       "      <th>zakat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040944</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370893</td>\n",
       "      <td>0.074179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039316</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043070</td>\n",
       "      <td>0.15667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027929</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.044108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049119</td>\n",
       "      <td>0.049119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098239</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.034208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 712 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abstrak      acak accelerated    adanya    adapun  adequacy  agregasi  \\\n",
       "1   0.047839  0.000000    0.000000  0.068102  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000    0.047506  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.052310  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.050230  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000    0.000000  0.000000  0.036626  0.000000  0.000000   \n",
       "10  0.040137  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000    0.000000  0.000000  0.046473  0.000000  0.000000   \n",
       "12  0.000000  0.000000    0.000000  0.000000  0.000000  0.131096  0.000000   \n",
       "13  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.049119   \n",
       "14  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.051496    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "          ak  akademik     aktif  ...  variatif    volume    warung wawancara  \\\n",
       "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.037444   \n",
       "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  ...  0.000000  0.223403  0.000000  0.040944   \n",
       "5   0.000000  0.370893  0.074179  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.039316   \n",
       "7   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.043070   \n",
       "8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.027929   \n",
       "9   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.031416   \n",
       "11  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "13  0.049119  0.000000  0.000000  ...  0.000000  0.000000  0.098239  0.027007   \n",
       "14  0.000000  0.000000  0.000000  ...  0.039395  0.000000  0.000000  0.000000   \n",
       "15  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       well  whatsapp   wiersma    window yulistiana     zakat  \n",
       "1   0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "2   0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "3   0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "4   0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "5   0.00000  0.000000  0.000000  0.074179   0.000000  0.000000  \n",
       "6   0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "7   0.15667  0.000000  0.000000  0.000000   0.000000  0.313341  \n",
       "8   0.00000  0.044108  0.000000  0.000000   0.000000  0.000000  \n",
       "9   0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "10  0.00000  0.000000  0.000000  0.000000   0.057138  0.000000  \n",
       "11  0.00000  0.000000  0.053519  0.000000   0.000000  0.000000  \n",
       "12  0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "13  0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "14  0.00000  0.034208  0.000000  0.000000   0.000000  0.000000  \n",
       "15  0.00000  0.000000  0.000000  0.000000   0.000000  0.000000  \n",
       "\n",
       "[15 rows x 712 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfb = pd.DataFrame(data=tf,index=list(range(1, len(tf[:,1])+1, )),columns=[a])\n",
    "dfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd813b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0925690e",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "966d61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff38be81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04783853 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.04750616 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.05149611 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#--- Mengubah Variabel Data Frame Menjadi Array ---\n",
    "x_array =  np.array(dfb)\n",
    "print(x_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02ee55",
   "metadata": {},
   "source": [
    "## LSA\n",
    "Latent Semantic Analysis (LSA) merupakan sebuah metode yang memanfaatkan model statistik matematis untuk menganalisa struktur semantik suatu teks. LSA bisa digunakan untuk menilai esai dengan mengkonversikan esai menjadi matriks-matriks yang diberi nilai pada masing-masing term untuk dicari kesamaan dengan term referensi. LSA pada dasarnya adalah dekomposisi nilai tunggal.\n",
    "\n",
    "Singular Value Decomposition (SVD) adalah salah satu teknik reduksi dimensi yang bermanfaat untuk memperkecil nilai kompleksitas dalam pemrosesan term-document matrix. SVD merupakan teorema aljabar linier yang menyebutkan bahwa persegi panjang dari term-document matrix dapat dipecah/didekomposisikan menjadi tiga matriks, yaitu :\n",
    "\n",
    "– Matriks ortogonal U (matriks dokumen-topik)\n",
    "\n",
    "– Matriks diagonal S (Matrik diagonal dengan elemen matriks positif atau nol)\n",
    "\n",
    "– Transpose dari matriks ortogonal V (matriks topik-term)\n",
    "\n",
    "Yang dirumuskan dengan :\n",
    "$$\n",
    "A_{m n}=U_{m m} x S_{m n} x V_{n n}^{T}\n",
    "$$\n",
    "\n",
    "Keterangan : \n",
    "A = Matriks Masukan (Pada Penelitian matriks ini berisi matrik hasil perhitungan TF-IDF)\n",
    "\n",
    "U = Matriks Ortogonal U\n",
    "\n",
    "S = Matriks Diagonal S (matriks positif atau nol)\n",
    "\n",
    "V =  Transpose Ortogonal V\n",
    "\n",
    "\n",
    "Setiap baris dari matriks U (matriks istilah dokumen) adalah representasi vektor dari dokumen yang sesuai. Panjang vektor ini adalah jumlah topik yang diinginkan. Representasi vektor untuk suku-suku dalam data kami dapat ditemukan dalam matriks V (matriks istilah-topik).\n",
    "\n",
    "Jadi, SVD memberi kita vektor untuk setiap dokumen dan istilah dalam data kita. Panjang setiap vektor adalah k. Kami kemudian dapat menggunakan vektor-vektor ini untuk menemukan kata-kata dan dokumen serupa menggunakan metode kesamaan kosinus.\n",
    "\n",
    "Kita dapat menggunakan fungsi truncatedSVD untuk mengimplementasikan LSA. Parameter n_components adalah jumlah topik yang ingin kita ekstrak. Model tersebut kemudian di fit dan ditransformasikan pada hasil yang diberikan oleh vectorizer.\n",
    "\n",
    "Terakhir perhatikan bahwa LSA dan LSI (I untuk pengindeksan) adalah sama dan yang terakhir kadang-kadang digunakan dalam konteks pencarian informasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02668102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba892e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.11605737e-02  2.44100425e-01  2.42634424e-04 -2.91946426e-01\n",
      "  -1.05966812e-01  3.47203932e-01 -2.35408690e-01  1.97805561e-01\n",
      "   3.08195727e-01  3.58289265e-05]\n",
      " [-3.31245963e-05 -1.83675709e-04 -3.50062244e-04 -9.51883543e-05\n",
      "   1.08897709e-03 -9.42945428e-03  1.16533567e-02  3.07078368e-03\n",
      "  -1.65778807e-02  3.33474672e-01]\n",
      " [-7.21039009e-05 -5.69364583e-04  8.12835163e-01 -4.51938909e-04\n",
      "   6.46878225e-04 -1.01586252e-02  8.25710239e-03  1.22425049e-03\n",
      "   3.96578422e-04 -3.02486033e-04]\n",
      " [ 1.98831992e-01  6.16447005e-01 -2.39882067e-03 -8.88450045e-02\n",
      "  -1.56149133e-01 -2.59008932e-01 -1.21159593e-01  5.43457004e-02\n",
      "  -1.04913093e-01 -2.06388741e-04]\n",
      " [ 1.08430119e-04  6.13016133e-04  8.89682122e-04  7.74685026e-04\n",
      "  -2.68261238e-03  2.69252793e-02 -2.86561224e-02 -9.94791626e-03\n",
      "   4.05761564e-02  1.39950791e-01]\n",
      " [ 1.60178470e-02  7.18214760e-02  9.81473497e-04 -1.68580835e-01\n",
      "   8.44908471e-02  4.72829580e-01 -1.06315446e-01 -1.98270453e-01\n",
      "  -2.10672417e-01 -6.40663594e-05]\n",
      " [ 7.77653996e-01 -3.07576137e-01 -5.67750745e-04 -1.12907100e-01\n",
      "  -1.49102449e-02 -1.05951486e-02  1.01927269e-02  7.80276817e-02\n",
      "  -4.24751532e-02  5.54143272e-04]\n",
      " [ 5.49761638e-02  2.19518674e-01 -6.59603506e-04 -2.62253893e-01\n",
      "  -8.98642674e-02  2.70136315e-01 -1.41859729e-01  1.01526744e-01\n",
      "  -1.65086451e-01  6.66874018e-07]\n",
      " [ 1.78959009e-01  5.25593881e-01  1.34811990e-03  5.70843376e-02\n",
      "  -1.58523206e-01 -3.05813844e-01 -3.57860991e-01  2.76402684e-02\n",
      "  -1.21987424e-01  2.93878295e-04]\n",
      " [-4.32057861e-06 -2.60842574e-05 -1.00623238e-05 -7.93097126e-05\n",
      "   1.72110638e-05 -7.02795413e-04  2.17219808e-04  3.99700687e-04\n",
      "  -1.19332559e-04  9.32312579e-01]\n",
      " [ 6.47861058e-01 -2.78119483e-01  4.09543650e-04 -1.45655826e-01\n",
      "  -2.75451319e-02 -5.44662964e-03  8.88915729e-03  1.85030829e-01\n",
      "  -1.04465855e-01 -4.03344442e-04]\n",
      " [ 3.00687267e-01  4.08379214e-01  1.92698072e-03  4.86711424e-01\n",
      "   7.17620307e-02  4.00878121e-02 -3.92724880e-02 -3.52566407e-01\n",
      "   1.75387113e-01 -1.96970635e-05]\n",
      " [ 6.47052553e-02  2.61928513e-01  4.15337962e-04 -3.71735598e-01\n",
      "   3.36265404e-01  3.82984365e-02  1.05991856e-01  2.85884310e-02\n",
      "  -1.73117544e-01  3.80298367e-05]\n",
      " [ 7.39567204e-03  3.68050588e-02 -1.70367404e-03 -1.48241891e-01\n",
      "   6.52239998e-01 -2.10457087e-01 -7.39341201e-02 -1.47309625e-02\n",
      "   8.26313217e-02 -2.02017169e-05]\n",
      " [ 1.45226869e-01  2.99172525e-01 -1.55168819e-03  5.76050729e-01\n",
      "   2.18432876e-01  2.19679459e-01  1.04625986e-01  2.02563432e-01\n",
      "  -3.43953587e-02  2.70110900e-05]\n",
      " [ 5.55892622e-03  2.60287825e-02 -1.30289613e-03 -6.33998033e-02\n",
      "  -3.61780620e-02  1.55008376e-01 -1.79231642e-01  2.32340923e-01\n",
      "   7.75706179e-01 -3.03639305e-05]\n",
      " [ 9.54732167e-03  4.12753031e-02 -1.42298193e-03 -9.84137186e-02\n",
      "  -6.54385599e-03  3.67674878e-01 -1.09649389e-01 -1.87868310e-01\n",
      "  -8.40350535e-02  3.13534292e-04]\n",
      " [ 6.36749853e-02  1.91581484e-01 -1.96215221e-03 -1.27716671e-01\n",
      "   6.60185384e-02  3.48663024e-01  1.73136259e-01 -4.49174628e-01\n",
      "  -2.08777792e-04 -8.63174511e-05]\n",
      " [ 7.80132933e-03  3.89818679e-02  2.07623798e-03 -1.47352521e-01\n",
      "   6.43291962e-01 -1.46236209e-01 -1.31077653e-01 -2.82098879e-02\n",
      "   1.19258085e-01  4.31010158e-05]\n",
      " [ 9.84668839e-02  3.82310168e-01  1.83012378e-03 -3.60839848e-01\n",
      "  -9.49531329e-02 -1.02725701e-01  3.96148551e-01  2.35010207e-01\n",
      "   9.18911709e-03 -1.00219639e-04]\n",
      " [ 3.44498887e-02  8.37170186e-02  4.22083105e-04  3.17324621e-01\n",
      "   2.08546324e-01  3.30557533e-01  2.17199597e-01  5.70641444e-01\n",
      "  -1.74512789e-01 -1.23172422e-06]\n",
      " [ 6.04100397e-01 -1.22629514e-01 -6.20711489e-05  1.00699775e-01\n",
      "   2.79146092e-02  1.21228565e-02 -1.57598226e-02 -2.31364605e-01\n",
      "   1.39071782e-01 -2.94263361e-04]\n",
      " [ 6.16515647e-02  1.88809308e-01  6.17502601e-04 -9.61192243e-02\n",
      "  -7.48274701e-02 -7.42279758e-02  7.09248074e-01 -1.56718853e-01\n",
      "   2.67844859e-01  1.16517724e-04]\n",
      " [ 5.15801202e-05  4.25363150e-04  8.14207571e-01  5.13333068e-04\n",
      "  -9.26331255e-04  1.14764444e-02 -9.07078896e-03 -1.38686249e-03\n",
      "  -5.55364036e-05  3.03843845e-04]]\n",
      "(24, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d84cc2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  6.116057373418446\n",
      "Topic  1  :  24.41004252697031\n",
      "Topic  2  :  0.02426344235968518\n",
      "Topic  3  :  -29.19464255088084\n",
      "Topic  4  :  -10.596681197354268\n",
      "Topic  5  :  34.72039320719818\n",
      "Topic  6  :  -23.540869002625094\n",
      "Topic  7  :  19.78055606267261\n",
      "Topic  8  :  30.819572658873707\n",
      "Topic  9  :  0.0035828926454230304\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "  print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c9d101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 260)\n",
      "[[ 1.11251518e-01  8.88116115e-03  1.15528592e-02 ...  2.11244770e-01\n",
      "   8.88116115e-03  1.06426565e-02]\n",
      " [-5.05469989e-02  3.75837339e-02  3.68358271e-02 ... -9.20850170e-02\n",
      "   3.75837339e-02  4.56465328e-02]\n",
      " [ 2.14139996e-04 -1.50221304e-04 -5.78582067e-04 ...  4.25212131e-06\n",
      "  -1.50221304e-04  1.05293815e-04]\n",
      " ...\n",
      " [ 4.83988825e-02  2.51548770e-02 -1.24364226e-01 ...  6.01298656e-02\n",
      "   2.51548770e-02  7.43386203e-03]\n",
      " [-2.74185653e-02 -4.19923860e-02 -7.12104750e-04 ... -3.44729425e-02\n",
      "  -4.19923860e-02 -4.46878005e-02]\n",
      " [-2.20330614e-04  1.95253370e-06 -2.73702698e-05 ...  5.51152996e-05\n",
      "   1.95253370e-06  1.75435274e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1b62a",
   "metadata": {},
   "source": [
    "Sekarang bisa mendapatkan daftar kata-kata penting untuk masing-masing dari 12 topik seperti yang ditunjukkan. Untuk kesederhanaan di sini saya telah menunjukkan 10 kata untuk setiap topik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06f5398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "polri bareskrim dilaporkan gilang juragan pramana widya dugaan penipuan terkait pemeriksaan penyidik \n",
      "\n",
      "Topic 1: \n",
      "pemilu pemilihan komisi ketua selasa korupsi pemberantasan ilham jadwal melanjutkan penundaan saputra \n",
      "\n",
      "Topic 2: \n",
      "jenderal panglima perkasa andika dipelajari konflik perkembangan rusiaukraina dilantik februari komandan korps \n",
      "\n",
      "Topic 3: \n",
      "negeri korupsi pemberantasan komisi pemeriksaan penyidik mantan mengagendakan romahurmuziy hakim hidayat isnaeni \n",
      "\n",
      "Topic 4: \n",
      "fadjar marsekal kepala menjelang college defence ksau kunjungan nostalgia prasetyo staf udara \n",
      "\n",
      "Topic 5: \n",
      "indonesia negeri negara fraksi dunia demokrasi nasional diduga ektp menyelidiki merugikan pengadaan \n",
      "\n",
      "Topic 6: \n",
      "partai gerindra bersamaan capres dijagokan kader prabowo sandiaga subianto negeri ketua politik \n",
      "\n",
      "Topic 7: \n",
      "negeri arab liga maret peristiwa sejarah tanggal berdirinya pemilu fraksi nasional dilaporkan \n",
      "\n",
      "Topic 8: \n",
      "nasional ekonomi hukum intelektual kekayaan kemenkumham kementerian komitmen manusia mendorong mendukung pemerintah \n",
      "\n",
      "Topic 9: \n",
      "alhikam barat depok digelar hasyim haul jawa masjid minggu muzadi pesantren puncak \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:12]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d903d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}